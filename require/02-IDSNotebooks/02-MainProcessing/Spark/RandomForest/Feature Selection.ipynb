{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12a3e66-2d66-4a8f-9209-fc4f66af6ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /opt/conda/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: pymongo in /opt/conda/lib/python3.9/site-packages (4.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install findspark pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b7bd0a-097f-4158-8f91-3c093056e780",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Crate Directory and Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff724c2-937c-4550-84dc-118750d3f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use '/resource' to syncronize folder with host\n",
    "\n",
    "!mkdir -p ~/output/spark-model/random-forest/feature-importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b08d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path  = '/home/jovyan/output/renamed-data/multi/TrainDataUnderSampling.csv'\n",
    "output_path = '/home/jovyan/output/spark-model/random-forest/feature-importance'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bafb409-6172-4d0e-9e54-38c5bd03de20",
   "metadata": {},
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d29106af-d5f6-4ed1-9a49-a082dd6c17ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import pyspark\n",
    "import findspark\n",
    "from gridfs import GridFS\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b91b4-2419-41d4-a5d4-2d7f04f6637e",
   "metadata": {},
   "source": [
    "# DB Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3669d037-59c3-4567-a784-ed786aadfbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://mongodb:27017\")\n",
    "db = client['mataelanglab']\n",
    "\n",
    "result_col = db['spark_result']\n",
    "cv_col = db['spark_cv']\n",
    "model_col = GridFS(db, 'spark_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d203af4-47e9-4977-afa7-89fea7ff58df",
   "metadata": {},
   "source": [
    "# Spark session & context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2508811-ab7c-40c4-b5ff-f236bae08ceb",
   "metadata": {},
   "source": [
    "## Local Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee03da1-93e8-4b2e-bfac-5d83cf5cac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master('local[2]')\n",
    "         .appName('RandomForest-FeatureImportance')\n",
    "         .config(\"spark.executor.memory\", \"4g\") #optional\n",
    "         .config(\"spark.executor.cores\",\"1\") #optional\n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57661ef8-7bcc-4224-8d73-3309d3f85fe9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cluster Version\n",
    "\n",
    "<b>Note : </b> \\\n",
    "Jika menggunakan mode ini pastikan data dapat diakses oleh masing worker yang ada. \\\n",
    "Apabila menggunakan cluster pada MataElangLab (1 master dan 1 worker), taruh data pada '/resource'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b14ab7a-a582-4950-ae03-4504ce89b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_uri = os.environ['SPARK_MASTER']\n",
    "print(spark_uri) #MataElangLab Spark Cluster URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c26f66-0692-4052-bb13-66f8332779e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master(spark_uri)\n",
    "         .appName('RandomForest-FeatureImportance')\n",
    "         .config(\"spark.executor.memory\", \"2g\") #optional\n",
    "         .config(\"spark.executor.cores\",\"1\") #optional\n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe1572-f788-4293-85cb-fcff378607c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b94b0cce-fc7d-4953-8560-523034e1b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(input_path, header=\"true\", inferSchema =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ad4a6-03a2-463f-b0b8-863774d0c61b",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0a62fd-f3d4-4084-a957-bf453e50418a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.select([F.col(column).cast('double') for column in df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c1c40a-fd1a-4740-afb8-ea64acaa18d4",
   "metadata": {},
   "source": [
    "# Classification Using Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1b4ea80-c961-4b4e-ad26-aef86dbb494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = [\n",
    "    'idle_max',\n",
    "    'idle_mean',\n",
    "    'idle_min',\n",
    "    'fwd_packet_length_min',\n",
    "    'idle_std',\n",
    "    'packet_length_min',\n",
    "    'fwd_init_win_bytes',\n",
    "    'fwd_iat_min',\n",
    "    'fin_flag_count',\n",
    "    'fwd_iat_total'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ef975-7e58-432e-ba45-4b80b2fc8927",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04f6e140-12b4-4ea5-bd2d-3ff3f6cf4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector Assembler\n",
    "vector_assembler = VectorAssembler(inputCols=feature, outputCol=\"SS_features\")\n",
    "df = vector_assembler.transform(df)\n",
    "\n",
    "#Standard Scaler\n",
    "scaler = StandardScaler(inputCol=\"SS_features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False)\n",
    "df = scaler.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d92d3-bc33-4298-aae2-5c381fed7d47",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08df1ca6-14ce-4708-9f34-a2330ad1cfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 6208\n",
      "Test Dataset Count: 2532\n",
      "--- 17.23194146156311 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Split the data\n",
    "(training_data, test_data) = df.randomSplit([0.7,0.3], 42)\n",
    "print(\"Training Dataset Count: \" + str(training_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))\n",
    "\n",
    "# Create Random Forest Classifier object\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"scaledFeatures\")\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "rfModel = rf.fit(training_data)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "rf_predictions = rfModel.transform(test_data)\n",
    "duration = (time.time() - start_time)\n",
    "print(\"--- %s seconds ---\" % duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7d47f91-9721-4b6d-9e70-c9769f4a3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix : [458   0   1   2  17   1 513   0   0   0   2   0 513   0   0   0   2   7\n",
      " 476   0  62   0   0   0 478]\n",
      "accuracy :  0.9629\n",
      "recall : 0.9629\n",
      "precision :  0.9645\n",
      "f1-measure : 0.9629\n"
     ]
    }
   ],
   "source": [
    "# Calculate Confusion matrix\n",
    "ypred = rf_predictions.select(\"prediction\").collect()\n",
    "ytest = rf_predictions.select(\"label\").collect()\n",
    "\n",
    "acc_eval    = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "recall_eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "prec_eval   = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "f1_eval     = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "accuracy    = acc_eval.evaluate(rf_predictions)\n",
    "recall      = recall_eval.evaluate(rf_predictions)\n",
    "precision   = prec_eval.evaluate(rf_predictions)\n",
    "f1_score    = f1_eval.evaluate(rf_predictions)\n",
    "\n",
    "print(\"confusion matrix :\",confusion_matrix(ytest, ypred).ravel())\n",
    "print(str('accuracy :  %0.4f' % accuracy) +\"\\n\" + str('recall : %0.4f' % recall) +\n",
    "      \"\\n\" + str('precision :  %0.4f' %precision) + \"\\n\" + str('f1-measure : %0.4f' %f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f60a0ed5-e369-4edd-a9a7-7c951b083da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "ml_path = output_path+\"/model\"\n",
    "ss_path = output_path+\"/standard-scaler\"\n",
    "\n",
    "!rm -rf $ml_path $ss_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f24987f-219a-48d5-85f4-c938201e13e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rfModel.save(ml_path)\n",
    "scaler.save(ss_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "add8a9f1-2803-41ed-af91-b7f974096cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x7f18d0070a00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store to MongoDB\n",
    "\n",
    "# with open(path, \"rb\") as f:\n",
    "#     model_col.put(f, filename=\"spark-all-feature\")\n",
    "    \n",
    "result_col.insert_one({\n",
    "    'machine_learning': \"Random Forest\",\n",
    "    'feature': \"Feature Importance\",\n",
    "    'label': \"Multi-Label\",\n",
    "    'duration': duration,\n",
    "    'accuracy': accuracy,\n",
    "    'recall': recall,\n",
    "    'precision': precision,\n",
    "    'f1_score': f1_score,\n",
    "    'created_at': datetime.fromtimestamp(time.time())\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44b9ee1c-2733-41a4-b462-01002324feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c865725-8f91-4755-bdd9-ff54d7145e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
