{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12a3e66-2d66-4a8f-9209-fc4f66af6ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /opt/conda/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: pymongo in /opt/conda/lib/python3.9/site-packages (4.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install findspark pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b7bd0a-097f-4158-8f91-3c093056e780",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Crate Directory and Output File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ff724c2-937c-4550-84dc-118750d3f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use '/resource' to syncronize folder with host\n",
    "\n",
    "!mkdir -p ~/output/spark-model/random-forest/pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b08d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path  = '/home/jovyan/output/renamed-data/multi/TrainDataUnderSampling.csv'\n",
    "output_path = '/home/jovyan/output/spark-model/random-forest/pca'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bafb409-6172-4d0e-9e54-38c5bd03de20",
   "metadata": {},
   "source": [
    "# Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d29106af-d5f6-4ed1-9a49-a082dd6c17ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import pyspark\n",
    "import findspark\n",
    "from gridfs import GridFS\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b91b4-2419-41d4-a5d4-2d7f04f6637e",
   "metadata": {},
   "source": [
    "# DB Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3669d037-59c3-4567-a784-ed786aadfbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://mongodb:27017\")\n",
    "db = client['mataelanglab']\n",
    "\n",
    "result_col = db['spark_result']\n",
    "cv_col = db['spark_cv']\n",
    "model_col = GridFS(db, 'spark_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d203af4-47e9-4977-afa7-89fea7ff58df",
   "metadata": {},
   "source": [
    "# Spark session & context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a39d1a-1031-4f49-82c0-188dc4bd4051",
   "metadata": {},
   "source": [
    "## Local Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee03da1-93e8-4b2e-bfac-5d83cf5cac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master('local[2]')\n",
    "         .appName('RandomForest-PCA')\n",
    "         .config(\"spark.executor.memory\", \"4g\") #optional\n",
    "         .config(\"spark.executor.cores\",\"1\") #optional\n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead434d-01f0-4519-a469-6c2eecb59a42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Cluster Version\n",
    "\n",
    "<b>Note : </b> \\\n",
    "Jika menggunakan mode ini pastikan data dapat diakses oleh masing worker yang ada. \\\n",
    "Apabila menggunakan cluster pada MataElangLab (1 master dan 1 worker), taruh data pada '/resource'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70491399-a285-4f7c-93b2-69d78398cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_uri = os.environ['SPARK_MASTER']\n",
    "print(spark_uri) #MataElangLab Spark Cluster URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f9b86-64ae-407c-9298-f60b6b6234ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master(spark_uri)\n",
    "         .appName('RandomForest-PCA')\n",
    "         .config(\"spark.executor.memory\", \"2g\") #optional\n",
    "         .config(\"spark.executor.cores\",\"1\") #optional\n",
    "         .getOrCreate())\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe1572-f788-4293-85cb-fcff378607c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b94b0cce-fc7d-4953-8560-523034e1b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(input_path, header=\"true\", inferSchema =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59ad4a6-03a2-463f-b0b8-863774d0c61b",
   "metadata": {},
   "source": [
    "# Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da0a62fd-f3d4-4084-a957-bf453e50418a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.select([F.col(column).cast('double') for column in df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c1c40a-fd1a-4740-afb8-ea64acaa18d4",
   "metadata": {},
   "source": [
    "# Classification Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9497bd0-1860-4c6f-b393-75df55a4ef48",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = [\n",
    "    'flow_duration',\n",
    "\t'total_fwd_packet',\n",
    "\t'total_bwd_packets',\n",
    "\t'total_length_of_fwd_packet',\n",
    "\t'total_length_of_bwd_packet',\n",
    "\t'fwd_packet_length_max',\n",
    "\t'fwd_packet_length_min',\n",
    "\t'fwd_packet_length_mean',\n",
    "\t'fwd_packet_length_std',\n",
    "\t'bwd_packet_length_max',\n",
    "\t'bwd_packet_length_min',\n",
    "\t'bwd_packet_length_mean',\n",
    "\t'bwd_packet_length_std',\n",
    "\t'flow_bytes_per_s',\n",
    "\t'flow_packets_per_s',\n",
    "\t'flow_iat_mean',\n",
    "\t'flow_iat_std',\n",
    "\t'flow_iat_max',\n",
    "\t'flow_iat_min',\n",
    "\t'fwd_iat_total',\n",
    "\t'fwd_iat_mean',\n",
    "\t'fwd_iat_std',\n",
    "\t'fwd_iat_max',\n",
    "\t'fwd_iat_min',\n",
    "\t'bwd_iat_total',\n",
    "\t'bwd_iat_mean',\n",
    "\t'bwd_iat_std',\n",
    "\t'bwd_iat_max',\n",
    "\t'bwd_iat_min',\n",
    "\t'fwd_psh_flags',\n",
    "\t'bwd_psh_flags',\n",
    "\t'fwd_urg_flags',\n",
    "\t'bwd_urg_flags',\n",
    "\t'fwd_header_length',\n",
    "\t'bwd_header_length',\n",
    "\t'fwd_packets_per_s',\n",
    "\t'bwd_packets_per_s',\n",
    "\t'packet_length_min',\n",
    "\t'packet_length_max',\n",
    "\t'packet_length_mean',\n",
    "\t'packet_length_std',\n",
    "\t'packet_length_variance',\n",
    "\t'fin_flag_count',\n",
    "\t'syn_flag_count',\n",
    "\t'rst_flag_count',\n",
    "\t'psh_flag_count',\n",
    "\t'ack_flag_count',\n",
    "\t'urg_flag_count',\n",
    "\t'cwr_flag_count',\n",
    "\t'ece_flag_count',\n",
    "\t'down_per_up_ratio',\n",
    "\t'average_packet_size',\n",
    "\t'fwd_segment_size_avg',\n",
    "\t'bwd_segment_size_avg',\n",
    "\t'fwd_bytes_per_bulk_avg',\n",
    "\t'fwd_packet_per_bulk_avg',\n",
    "\t'fwd_bulk_rate_avg',\n",
    "\t'bwd_bytes_per_bulk_avg',\n",
    "\t'bwd_packet_per_bulk_avg',\n",
    "\t'bwd_bulk_rate_avg',\n",
    "\t'subflow_fwd_packets',\n",
    "\t'subflow_fwd_bytes',\n",
    "\t'subflow_bwd_packets',\n",
    "\t'subflow_bwd_bytes',\n",
    "\t'fwd_init_win_bytes',\n",
    "\t'bwd_init_win_bytes',\n",
    "\t'fwd_act_data_pkts',\n",
    "\t'fwd_seg_size_min',\n",
    "\t'active_mean',\n",
    "\t'active_std',\n",
    "\t'active_max',\n",
    "\t'active_min',\n",
    "\t'idle_mean',\n",
    "\t'idle_std',\n",
    "\t'idle_max',\n",
    "\t'idle_min',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ef975-7e58-432e-ba45-4b80b2fc8927",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04f6e140-12b4-4ea5-bd2d-3ff3f6cf4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vector Assembler\n",
    "vector_assembler = VectorAssembler(inputCols=feature, outputCol=\"SS_features\")\n",
    "df = vector_assembler.transform(df)\n",
    "\n",
    "#Standard Scaler\n",
    "scaler = StandardScaler(inputCol=\"SS_features\", outputCol=\"scaledFeatures\", withStd=True, withMean=False).fit(df)\n",
    "df = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ca8268-379c-432f-9845-e662cb811b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k=7, inputCol=\"scaledFeatures\", outputCol=\"pcaFeatures\").fit(df)\n",
    "df = pca.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6d92d3-bc33-4298-aae2-5c381fed7d47",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04c1e8ef-4694-4477-b1e2-b25f43dece0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 6208\n",
      "Test Dataset Count: 2532\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "(training_data, test_data) = df.randomSplit([0.7,0.3], 42)\n",
    "print(\"Training Dataset Count: \" + str(training_data.count()))\n",
    "print(\"Test Dataset Count: \" + str(test_data.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "365ae689-ff88-4949-9475-0ba7f2c37b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 35.990607500076294 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Create Random Forest Classifier object\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"pcaFeatures\")\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "rfModel = rf.fit(training_data)\n",
    "\n",
    "fit_duration = (time.time() - start_time)\n",
    "print(\"--- %s seconds ---\" % fit_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeaaf058-a896-41f1-a40f-fba40be9aebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.1096503734588623 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#Predict the response for test dataset\n",
    "rf_predictions = rfModel.transform(test_data)\n",
    "\n",
    "pred_duration = (time.time() - start_time)\n",
    "print(\"--- %s seconds ---\" % pred_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7d47f91-9721-4b6d-9e70-c9769f4a3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix : [367  42   2  38  29  27 388   3  96   0  50  49 274 142   0  66  17   6\n",
      " 396   0  53  20   0   3 464]\n",
      "accuracy :  0.7461\n",
      "recall : 0.7461\n",
      "precision :  0.7844\n",
      "f1-measure : 0.7478\n"
     ]
    }
   ],
   "source": [
    "# Calculate Confusion matrix\n",
    "ypred = rf_predictions.select(\"prediction\").collect()\n",
    "ytest = rf_predictions.select(\"label\").collect()\n",
    "\n",
    "acc_eval    = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "recall_eval = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "prec_eval   = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "f1_eval     = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "accuracy    = acc_eval.evaluate(rf_predictions)\n",
    "recall      = recall_eval.evaluate(rf_predictions)\n",
    "precision   = prec_eval.evaluate(rf_predictions)\n",
    "f1_score    = f1_eval.evaluate(rf_predictions)\n",
    "\n",
    "print(\"confusion matrix :\",confusion_matrix(ytest, ypred).ravel())\n",
    "print(str('accuracy :  %0.4f' % accuracy) +\"\\n\" + str('recall : %0.4f' % recall) +\n",
    "      \"\\n\" + str('precision :  %0.4f' %precision) + \"\\n\" + str('f1-measure : %0.4f' %f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f60a0ed5-e369-4edd-a9a7-7c951b083da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "ml_path = output_path+\"/model\"\n",
    "ss_path = output_path+\"/standard-scaler\"\n",
    "pca_path = output_path+\"/pca\"\n",
    "\n",
    "!rm -rf $ml_path $ss_path $pca_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f24987f-219a-48d5-85f4-c938201e13e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rfModel.save(ml_path)\n",
    "scaler.save(ss_path)\n",
    "pca.save(pca_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "add8a9f1-2803-41ed-af91-b7f974096cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x7fd64283f0d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store to MongoDB\n",
    "\n",
    "# with open(path, \"rb\") as f:\n",
    "#     model_col.put(f, filename=\"spark-all-feature\")\n",
    "    \n",
    "result_col.insert_one({\n",
    "    'machine_learning': \"Random Forest\",\n",
    "    'feature': \"PCA\",\n",
    "    'label': \"Multi-Label\",\n",
    "    'fit_duration': fit_duration,\n",
    "    'pred_duration': pred_duration,\n",
    "    'accuracy': accuracy,\n",
    "    'recall': recall,\n",
    "    'precision': precision,\n",
    "    'f1_score': f1_score,\n",
    "    'created_at': datetime.fromtimestamp(time.time())\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44b9ee1c-2733-41a4-b462-01002324feaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f21548-b3dc-4c24-b338-c740682103b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
